{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.regularizers import l2, activity_l2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss, auc, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adagrad,SGD,Adadelta\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import containers\n",
    "from keras.layers.core import Dense, AutoEncoder\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1778)  # for reproducibility\n",
    "need_normalise=True\n",
    "need_validataion=True\n",
    "need_categorical=False\n",
    "save_categorical_file=False\n",
    "nb_epoch=10\n",
    "golden_feature=[(\"CoverageField1B\",\"PropertyField21B\"),\n",
    "                (\"GeographicField6A\",\"GeographicField8A\"),\n",
    "                (\"GeographicField6A\",\"GeographicField13A\"),\n",
    "                (\"GeographicField8A\",\"GeographicField13A\"),\n",
    "                (\"GeographicField11A\",\"GeographicField13A\"),\n",
    "                (\"GeographicField8A\",\"GeographicField11A\")]\n",
    "\n",
    "def save2model(submission,file_name,y_pre):\n",
    "    assert len(y_pre)==len(submission)\n",
    "    submission['QuoteConversion_Flag']=y_pre\n",
    "    submission.to_csv(file_name,index=False)\n",
    "    print (\"saved files %s\" % file_name)\n",
    "    \n",
    "\n",
    "def save2model(submission,file_name,y_pre):\n",
    "    assert len(y_pre)==len(submission)\n",
    "    submission['QuoteConversion_Flag']=y_pre\n",
    "    submission.to_csv(file_name,index=False)\n",
    "    print (\"saved files %s\" % file_name)\n",
    "\n",
    "def getDummy(df,col):\n",
    "    category_values=df[col].unique()\n",
    "    data=[[0 for i in range(len(category_values))] for i in range(len(df))]\n",
    "    print data\n",
    "    dic_category=dict()\n",
    "    for i,val in enumerate(list(category_values)):\n",
    "        dic_category[str(val)]=i\n",
    "   # print dic_category\n",
    "    for i in range(len(df)):\n",
    "        data[i][dic_category[str(df[col][i])]]=1\n",
    "\n",
    "    data=np.array(data)\n",
    "    for i,val in enumerate(list(category_values)):\n",
    "        df.loc[:,\"_\".join([col,str(val)])]=data[:,i]\n",
    "\n",
    "    return df\n",
    "\n",
    "def generateFileName(model,params):\n",
    "     file_name=\"_\".join([(key+\"_\"+ str(val))for key,val in params.items()])\n",
    "     return model+\"_\"+file_name+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train=pd.read_csv('data/train.csv')\n",
    "    test=pd.read_csv('data/test.csv')\n",
    "    train = train.drop(['QuoteNumber','PropertyField6', 'GeographicField10A'], axis=1)\n",
    "    \n",
    "    submission=pd.DataFrame()\n",
    "    submission[\"QuoteNumber\"]= test[\"QuoteNumber\"]\n",
    "\n",
    "    train_y=train['QuoteConversion_Flag'].values\n",
    "    train=train.drop('QuoteConversion_Flag',axis=1)\n",
    "    \n",
    "    test = test.drop(['QuoteNumber','PropertyField6', 'GeographicField10A'],axis=1)\n",
    "    train['Date'] = pd.to_datetime(pd.Series(train['Original_Quote_Date']))\n",
    "    train = train.drop('Original_Quote_Date', axis=1)\n",
    "    train['Year'] = train['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "    train['Month'] = train['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "    train['weekday'] = [train['Date'][i].dayofweek for i in range(len(train['Date']))]\n",
    "    \n",
    "    test['Date'] = pd.to_datetime(pd.Series(test['Original_Quote_Date']))\n",
    "    test = test.drop('Original_Quote_Date', axis=1)\n",
    "    test['Year'] = test['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "    test['Month'] = test['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "    test['weekday'] = [test['Date'][i].dayofweek for i in range(len(test['Date']))]\n",
    "    \n",
    "    train = train.drop('Date', axis=1)\n",
    "    test = test.drop('Date', axis=1)\n",
    "    \n",
    "    #fill na, have no effect on need_categorical method\n",
    "    train = train.fillna(-1)\n",
    "    test = test.fillna(-1)\n",
    "    \n",
    "    for f in test.columns:#\n",
    "        if train[f].dtype=='object':\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(train[f])+list(test[f]))\n",
    "            train[f] = lbl.transform(list(train[f].values))\n",
    "            test[f] = lbl.transform(list(test[f].values))\n",
    "\n",
    "    #try to encode all params less than 100 to be category\n",
    "    # one column for each caterogy\n",
    "    if need_categorical:\n",
    "        #row bind train and test\n",
    "        x=train.append(test,ignore_index=True)\n",
    "        del train\n",
    "        del test\n",
    "        for f in x.columns:#\n",
    "            category_values= set(list(x[f].unique()))\n",
    "            if len(category_values)<4:\n",
    "                print (f)\n",
    "                x=getDummy(x,f)\n",
    "                #x.drop(f,axis=1)\n",
    "                #all_data.drop(f,axis=1)\n",
    "        test = x.iloc[260753:,]\n",
    "        train = x.iloc[:260753:,]\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    train_y = encoder.fit_transform(train_y).astype(np.int32)\n",
    "    train_y = np_utils.to_categorical(train_y)\n",
    "    #for featureA,featureB in golden_feature:\n",
    "    #    train.loc[:,\"_\".join([featureA,featureB,\"diff\"])]=train[featureA]-train[featureB]\n",
    "    #    test.loc[:,\"_\".join([featureA,featureB,\"diff\"])]=test[featureA]-test[featureB]        \n",
    "\n",
    "    print (\"processsing finished\")\n",
    "    valid=None\n",
    "    valid_y=None\n",
    "    train = np.array(train)\n",
    "    train = train.astype(np.float32)\n",
    "    test=np.array(test)\n",
    "    test=test.astype(np.float32)\n",
    "    if need_normalise:\n",
    "        scaler = StandardScaler().fit(train)\n",
    "        train = scaler.transform(train)\n",
    "        test = scaler.transform(test)\n",
    "    \n",
    "    if need_validataion:\n",
    "        train,valid,train_y,valid_y=train_test_split(train,train_y,test_size=20000,random_state=218)\n",
    "    return [(train,train_y),(test,submission),(valid,valid_y)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "datasets=load_data()\n",
    "X_train, y_train = datasets[0]\n",
    "X_test, submission = datasets[1]\n",
    "X_valid, y_valid = datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'classes')\n",
      "(297, 'dims')\n"
     ]
    }
   ],
   "source": [
    "nb_classes = y_train.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "dims = X_train.shape[1]\n",
    "print(dims, 'dims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1024, input_shape=(dims,)))\n",
    "model.add(Dropout(0.1))#    input dropout\n",
    "model.add(PReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(360))\n",
    "model.add(PReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(420))\n",
    "model.add(PReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "#opt=SGD(momentum=0.9)\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "10\n",
      "('best_score is:', -1)\n",
      "Epoch 1/1\n",
      "240753/240753 [==============================] - 124s - loss: 0.1866   \n",
      "20000/20000 [==============================] - 1s     \n",
      "(0, 0.96019883768713366)\n",
      "('best_score is:', 0.96019883768713366)\n",
      "Epoch 1/1\n",
      "240753/240753 [==============================] - 130s - loss: 0.1851   \n",
      "20000/20000 [==============================] - 1s     \n",
      "(1, 0.96051080146033141)\n",
      "('best_score is:', 0.96051080146033141)\n",
      "Epoch 1/1\n",
      "240753/240753 [==============================] - 115s - loss: 0.1832   \n",
      "20000/20000 [==============================] - 1s     \n",
      "(2, 0.96012779715055507)\n",
      "('best_score is:', 0.96051080146033141)\n",
      "Epoch 1/1\n",
      " 63232/240753 [======>.......................] - ETA: 89s - loss: 0.1802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-054002886409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#model.fit(X_train, y_train, nb_epoch=nb_epoch,batch_size=256,validation_split=0.01,callbacks=[early_stopping])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"best_score is:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0my_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongjian/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, show_accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    699\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                          \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m                          shuffle=shuffle, metrics=metrics)\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongjian/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, metrics)\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongjian/anaconda/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongjian/anaconda/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongjian/anaconda/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\b\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mnumdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hongjian/anaconda/lib/python2.7/site-packages/ipykernel/iostream.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "auc_scores=[]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
    "best_score=-1\n",
    "best_model=None\n",
    "threshold=0.9638\n",
    "print('Training model...')\n",
    "if need_validataion:\n",
    "    print nb_epoch\n",
    "    for i in range(nb_epoch):\n",
    "    #early_stopping=EarlyStopping(monitor='val_loss', patience=0, verbose=1)\n",
    "    #model.fit(X_train, y_train, nb_epoch=nb_epoch,batch_size=256,validation_split=0.01,callbacks=[early_stopping])\n",
    "        print (\"best_score is:\",best_score)\n",
    "        model.fit(X_train, y_train, nb_epoch=1,batch_size=256)\n",
    "        y_pre = model.predict_proba(X_valid)\n",
    "        scores = roc_auc_score(y_valid,y_pre)\n",
    "        auc_scores.append(scores)\n",
    "        print (i,scores)\n",
    "        if scores>best_score:\n",
    "            best_score=scores\n",
    "            best_model=model\n",
    "            if best_score>threshold:\n",
    "                y_pre = model.predict_proba(X_test)[:,1]\n",
    "                #save2model(submission,'keras_nn_test_'+str(best_score)+\".csv\", y_pre)\n",
    "    plt.plot(auc_scores)\n",
    "    plt.show()\n",
    "else:\n",
    "    model.fit(X_train, y_train, nb_epoch=nb_epoch, batch_size=256)\n",
    "\n",
    "if need_validataion:\n",
    "    model=best_model\n",
    "#print('Generating submission...')\n",
    "y_pre = model.predict_proba(X_test)[:,1]\n",
    "#print roc_auc_score(y_test,y_pre)\n",
    "save2model(submission, 'keras_nn_test.csv',y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch\n",
    "need_validataion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
